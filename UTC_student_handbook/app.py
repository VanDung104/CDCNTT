# -*- coding: utf-8 -*-
import time
from flask import Flask, render_template, request, jsonify, session, redirect, url_for, flash
from langchain.vectorstores import Chroma
from langchain.prompts import PromptTemplate
from langchain_google_genai import ChatGoogleGenerativeAI
from langchain.embeddings import HuggingFaceEmbeddings
from langchain_core.runnables import RunnablePassthrough, RunnableLambda, RunnableParallel
from langchain_core.output_parsers import StrOutputParser
import os
from dotenv import load_dotenv
from functools import wraps # Th√™m ƒë·ªÉ t·∫°o decorator
import traceback # Th√™m ƒë·ªÉ in l·ªói chi ti·∫øt

# --- Th√™m c√°c th∆∞ vi·ªán m·ªõi cho vi·ªác t√¨m ki·∫øm ·∫£nh ---
import torch
from PIL import Image
from transformers import AutoModel, AutoProcessor
import numpy as np
import pickle
import base64
import io

# --- Th√™m th∆∞ vi·ªán cho vi·ªác upload PDF v√† RAG m·ªõi ---
from langchain_community.document_loaders import PyPDFLoader
from langchain.text_splitter import RecursiveCharacterTextSplitter
from datetime import date
import shutil # ƒê·ªÉ x·ª≠ l√Ω file/th∆∞ m·ª•c
from werkzeug.utils import secure_filename # Th√™m import n√†y

# ==========================================================
# PH·∫¶N 1: C·∫§U H√åNH V√Ä BI·∫æN M√îI TR∆Ø·ªúNG
# ==========================================================
print("--- KH·ªûI ƒê·ªòNG ·ª®NG D·ª§NG TR·ª¢ L√ù SINH VI√äN ---")
load_dotenv()
GOOGLE_API_KEY = os.getenv("GOOGLE_API_KEY")
# L·∫•y th√¥ng tin admin v√† secret key t·ª´ .env
ADMIN_USERNAME = os.getenv("ADMIN_USERNAME", "admin")
ADMIN_PASSWORD = os.getenv("ADMIN_PASSWORD", "password123")
FLASK_SECRET_KEY = os.getenv("FLASK_SECRET_KEY", "a_very_secret_key_for_sessions_12345")

if not GOOGLE_API_KEY:
    raise ValueError("GOOGLE_API_KEY ch∆∞a ƒë∆∞·ª£c thi·∫øt l·∫≠p trong .env")
if FLASK_SECRET_KEY == "a_very_secret_key_for_sessions_12345":
    print("‚ö†Ô∏è C·∫¢NH B√ÅO: FLASK_SECRET_KEY ƒëang d√πng gi√° tr·ªã m·∫∑c ƒë·ªãnh. H√£y ƒë·∫∑t gi√° tr·ªã n√†y trong .env")

# --- C·∫•u h√¨nh c√°c ƒë∆∞·ªùng d·∫´n to√†n c·ª•c ---
PERSIST_DIRECTORY = "/mnt/d/Nam5ki1/CDCNTT/UTC_student_handbook/soTaySinhVien_v2_bkai3"
IMAGE_EMBEDDING_FILE = '/mnt/d/Nam5ki1/CDCNTT/UTC_student_handbook/ImageEmbeddings/page_embeddings.npy'
IMAGE_PAGE_LIST_FILE = '/mnt/d/Nam5ki1/CDCNTT/UTC_student_handbook/ImageEmbeddings/page_list.pkl'
TEMPLATE_FOLDER_PATH = "/mnt/d/Nam5ki1/CDCNTT/UTC_student_handbook/templates"
STATIC_FOLDER_PATH = "/mnt/d/Nam5ki1/CDCNTT/UTC_student_handbook/static"
UPLOAD_FOLDER = "/tmp/utc_pdf_uploads" 
os.makedirs(UPLOAD_FOLDER, exist_ok=True) 

# --- Kh·ªüi t·∫°o c√°c bi·∫øn to√†n c·ª•c ---
app = Flask(__name__,
             template_folder=TEMPLATE_FOLDER_PATH,
             static_folder=STATIC_FOLDER_PATH) # Th√™m static_folder
app.config['SECRET_KEY'] = FLASK_SECRET_KEY # C·∫•u h√¨nh secret key cho session
app.config['UPLOAD_FOLDER'] = UPLOAD_FOLDER

chain_is_ready = False
image_search_is_ready = False
# ... (C√°c bi·∫øn to√†n c·ª•c kh√°c) ...

# ===================================================================
# --- KH·ªêI 1: KH·ªûI T·∫†O C√ÅC TH√ÄNH PH·∫¶N LANGCHAIN (RAG V·ªöI RERANK) ---
# ===================================================================
try:
    print("üß† [1/3] ƒêang kh·ªüi t·∫°o h·ªá th·ªëng h·ªèi ƒë√°p vƒÉn b·∫£n (LangChain)...")
    embedding_fn = HuggingFaceEmbeddings(model_name="bkai-foundation-models/vietnamese-bi-encoder")
    vectorstore = Chroma(persist_directory=PERSIST_DIRECTORY, embedding_function=embedding_fn)
    char_splitter = RecursiveCharacterTextSplitter(chunk_size=1000, chunk_overlap=100)
    retriever = vectorstore.as_retriever(search_type="similarity", search_kwargs={"k": 50})

    def rerank_by_date(docs):
        sorted_docs = sorted(docs, key=lambda doc: date.fromisoformat(doc.metadata.get('date', '1970-01-01')), reverse=True)
        return sorted_docs[:15]

    def format_docs(docs):
        formatted_chunks = []
        for doc in docs:
            # L·∫•y ng√†y v√† t√™n file t·ª´ metadata
            date_str = doc.metadata.get('date', 'Kh√¥ng r√µ ng√†y')
            source = os.path.basename(doc.metadata.get('source', 'Kh√¥ng r√µ ngu·ªìn'))
            
            # T·∫°o ƒë·ªãnh d·∫°ng r√µ r√†ng ƒë·ªÉ AI ƒë·ªçc ƒë∆∞·ª£c
            # V√≠ d·ª•: [VƒÇN B·∫¢N NG√ÄY: 2024-12-01] N·ªôi dung...
            chunk_content = f"--- [T√ÄI LI·ªÜU NG√ÄY: {date_str}] [NGU·ªíN: {source}] ---\n{doc.page_content}"
            formatted_chunks.append(chunk_content)
        
        return "\n\n".join(formatted_chunks)

    chat = ChatGoogleGenerativeAI(
        model="gemini-2.5-flash",
        convert_system_message_to_human=True,
        google_api_key=GOOGLE_API_KEY,
        temperature=0.1
    )

    # --- C·∫¨P NH·∫¨T TEMPLATE ƒê·ªÇ NH·∫¨N L·ªäCH S·ª¨ CHAT ---
    TEMPLATE = '''B·∫°n l√† m·ªôt tr·ª£ l√Ω ·∫£o th√¢n thi·ªán v√† chuy√™n nghi·ªáp c·ªßa Tr∆∞·ªùng ƒê·∫°i h·ªçc Giao th√¥ng V·∫≠n t·∫£i (UTC).
    Nhi·ªám v·ª• c·ªßa b·∫°n l√† tr·∫£ l·ªùi c√¢u h·ªèi c·ªßa sinh vi√™n m·ªôt c√°ch ch√≠nh x√°c v√† r√µ r√†ng.
    S·ª≠ d·ª•ng c√°c th√¥ng tin sau:
    1. L·ªãch s·ª≠ tr√≤ chuy·ªán tr∆∞·ªõc ƒë√≥ (d√πng ƒë·ªÉ tham kh·∫£o n·∫øu c√¢u h·ªèi m·ªõi li√™n quan).
    2. Ng·ªØ c·∫£nh m·ªõi (d√πng ƒë·ªÉ tr·∫£ l·ªùi c√¢u h·ªèi m·ªõi).
    3. TUY·ªÜT ƒê·ªêI KH√îNG ƒë∆∞·ª£c g·ªôp th√¥ng tin c≈© v√† m·ªõi. H√£y coi th√¥ng tin c≈© l√† ƒë√£ h·∫øt hi·ªáu l·ª±c.

    **L·ªãch s·ª≠ tr√≤ chuy·ªán:**
    {chat_history}
    
    **Ng·ªØ c·∫£nh m·ªõi (t·ª´ t√†i li·ªáu):**
    ----------------
    {context}
    ----------------

    **C√¢u h·ªèi m·ªõi c·ªßa sinh vi√™n:**
    {question}

    **H∆∞·ªõng d·∫´n tr·∫£ l·ªùi:**
    - D·ª±a v√†o l·ªãch s·ª≠ v√† ng·ªØ c·∫£nh m·ªõi ƒë·ªÉ tr·∫£ l·ªùi c√¢u h·ªèi m·ªõi.
    - N·∫øu ng·ªØ c·∫£nh m·ªõi kh√¥ng ch·ª©a th√¥ng tin, h√£y n√≥i: "R·∫•t ti·∫øc, t√¥i kh√¥ng t√¨m th·∫•y th√¥ng tin v·ªÅ v·∫•n ƒë·ªÅ n√†y trong S·ªï tay sinh vi√™n ho·∫∑c c√°c t√†i li·ªáu ƒë∆∞·ª£c cung c·∫•p."
    - Gi·ªØ gi·ªçng vƒÉn chuy√™n nghi·ªáp nh∆∞ng th√¢n thi·ªán.
    
    TR·∫¢ L·ªúI:'''
    prompt_template = PromptTemplate.from_template(TEMPLATE)

    # --- C·∫¨P NH·∫¨T CHAIN ƒê·ªÇ NH·∫¨N DICTIONARY V√Ä TR·∫¢ V·ªÄ SOURCES ---
    # Chain n√†y nh·∫≠n input l√†: {"question": str, "chat_history": str}
    
    retrieval_and_rerank = RunnableParallel(
        question=lambda x: x['question'],
        chat_history=lambda x: x['chat_history'],
        retrieved_docs=(
            (lambda x: x['question']) # L·∫•y 'question' t·ª´ input
            | retriever 
            | RunnableLambda(rerank_by_date)
        )
    )
    
    setup_and_retrieval = RunnableParallel(
        context=lambda x: format_docs(x["retrieved_docs"]),
        question=lambda x: x["question"],
        chat_history=lambda x: x["chat_history"], # Chuy·ªÉn chat_history sang b∆∞·ªõc ti·∫øp theo
        sources=lambda x: x["retrieved_docs"]
    )
    
    answer_generation = RunnableParallel(
        answer=(
            prompt_template # ƒê√£ ch·ª©a c·∫£ 3 bi·∫øn (context, question, chat_history)
            | chat 
            | StrOutputParser()
        ),
        sources=lambda x: x["sources"]
    )
    
    chain = retrieval_and_rerank | setup_and_retrieval | answer_generation
    
    print("‚úÖ H·ªá th·ªëng RAG (v·ªõi rerank v√† b·ªô nh·ªõ chat) ƒë√£ kh·ªüi t·∫°o th√†nh c√¥ng.")
    chain_is_ready = True

except Exception as e:
    print(f"‚ùå L·ªói khi kh·ªüi t·∫°o c√°c th√†nh ph·∫ßn LangChain: {e}")
    traceback.print_exc()
    chain_is_ready = False


# =================================================================
# --- KH·ªêI 2: KH·ªûI T·∫†O T√åM KI·∫æM H√åNH ·∫¢NH (VINTERN-1B) ---
# =================================================================
# (Gi·ªØ nguy√™n kh·ªëi code g·ªëc c·ªßa b·∫°n, v√¨ n√≥ ƒë√£ ch·∫°y)
try:
    print("üñºÔ∏è  [2/3] ƒêang kh·ªüi t·∫°o h·ªá th·ªëng t√¨m ki·∫øm h√¨nh ·∫£nh...")
    device = "cuda" if torch.cuda.is_available() else "cpu"
    print(f"   -> S·ª≠ d·ª•ng thi·∫øt b·ªã: {device}")

    # 1. Load Model v√† Processor
    model_name = "5CD-AI/Vintern-Embedding-1B"
    image_processor = AutoProcessor.from_pretrained(model_name, trust_remote_code=True)
    image_model = AutoModel.from_pretrained(
        model_name,
        torch_dtype=torch.bfloat16,
        low_cpu_mem_usage=True,
        trust_remote_code=True,
    ).eval().to(device)

    # 2. Load pre-computed embeddings and page images
    if os.path.exists(IMAGE_EMBEDDING_FILE) and os.path.exists(IMAGE_PAGE_LIST_FILE):
        loaded_embeddings_np = np.load(IMAGE_EMBEDDING_FILE)
        with open(IMAGE_PAGE_LIST_FILE, 'rb') as f:
            page_list = pickle.load(f)

        # Chu·∫©n b·ªã list embeddings cho h√†m score_multi_vector
        image_embeddings_list_of_tensors = [torch.tensor(emb).to(device) for emb in loaded_embeddings_np]
        
        print(f"‚úÖ H·ªá th·ªëng t√¨m ki·∫øm h√¨nh ·∫£nh s·∫µn s√†ng. ƒê√£ t·∫£i {len(page_list)} trang.")
        image_search_is_ready = True
    else:
        print(f"‚ö†Ô∏è Error: Kh√¥ng t√¨m th·∫•y '{IMAGE_EMBEDDING_FILE}' ho·∫∑c '{IMAGE_PAGE_LIST_FILE}'.")
        image_search_is_ready = False

except Exception as e:
    print(f"‚ùå L·ªói khi kh·ªüi t·∫°o h·ªá th·ªëng t√¨m ki·∫øm h√¨nh ·∫£nh: {e}")
    traceback.print_exc()
    image_search_is_ready = False

# --- H√†m ti·ªán √≠ch t√¨m ki·∫øm ·∫£nh (Gi·ªØ nguy√™n logic c·ªßa b·∫°n) ---
def search_images(query, top_k=3):
    batch_queries = image_processor.process_queries([query])
    batch_queries["input_ids"] = batch_queries["input_ids"].to(device)
    batch_queries["attention_mask"] = batch_queries["attention_mask"].to(device).bfloat16()
    with torch.no_grad():
        query_embeddings = image_model(**batch_queries)
    
    scores = image_processor.score_multi_vector(query_embeddings, image_embeddings_list_of_tensors)[0]
    top_indices = scores.cpu().argsort(descending=True)[:top_k]
    
    results = []
    for idx_tensor in top_indices:
        idx = idx_tensor.item()
        score = scores[idx].item()
        image = page_list[idx]
        buffered = io.BytesIO()
        image.save(buffered, format="PNG")
        img_str = base64.b64encode(buffered.getvalue()).decode("utf-8")
        results.append({
            "score": score,
            "page_number": idx + 1, # Tr·∫£ v·ªÅ page_number (1-based)
            "image_base64": f"data:image/png;base64,{img_str}"
        })
    return results

# ==========================================================
# PH·∫¶N 3: LOGIC X√ÅC TH·ª∞C ADMIN (M·ªöI)
# ==========================================================
print("üîê [3/3] ƒêang thi·∫øt l·∫≠p c√°c route x√°c th·ª±c Admin...")
def admin_required(f):
    """Decorator ƒë·ªÉ b·∫£o v·ªá route, y√™u c·∫ßu ƒëƒÉng nh·∫≠p admin."""
    @wraps(f)
    def decorated_function(*args, **kwargs):
        if 'admin_logged_in' not in session:
            flash('B·∫°n c·∫ßn ƒëƒÉng nh·∫≠p ƒë·ªÉ truy c·∫≠p ch·ª©c nƒÉng n√†y.', 'warning')
            return redirect(url_for('login')) # Chuy·ªÉn h∆∞·ªõng v·ªÅ trang login
        return f(*args, **kwargs)
    return decorated_function

@app.route('/login', methods=['GET', 'POST'])
def login():
    """Trang ƒëƒÉng nh·∫≠p cho Admin."""
    if request.method == 'POST':
        username = request.form['username']
        password = request.form['password']
        if username == ADMIN_USERNAME and password == ADMIN_PASSWORD:
            session['admin_logged_in'] = True
            flash('ƒêƒÉng nh·∫≠p th√†nh c√¥ng!', 'success')
            return redirect(url_for('home')) # Chuy·ªÉn v·ªÅ trang ch·ªß
        else:
            flash('T√™n ƒëƒÉng nh·∫≠p ho·∫∑c m·∫≠t kh·∫©u kh√¥ng ƒë√∫ng.', 'danger')
    return render_template('login.html')

@app.route('/logout')
def logout():
    """ƒêƒÉng xu·∫•t Admin."""
    session.pop('admin_logged_in', None)
    flash('B·∫°n ƒë√£ ƒëƒÉng xu·∫•t.', 'info')
    return redirect(url_for('home'))
print("‚úÖ C√°c route Admin ƒë√£ s·∫µn s√†ng.")


# ==========================================================
# PH·∫¶N 4: C√ÅC ENDPOINTS C·ª¶A ·ª®NG D·ª§NG
# ==========================================================

def image_to_base64(pil_image):
    buffered = io.BytesIO()
    pil_image.save(buffered, format="PNG")
    return base64.b64encode(buffered.getvalue()).decode("utf-8")

@app.route('/')
def home():
    """Render trang ch·ªß, truy·ªÅn tr·∫°ng th√°i ƒëƒÉng nh·∫≠p v√†o template."""
    return render_template('index_admin.html', admin_logged_in=session.get('admin_logged_in', False))

# --- H√ÄM TI·ªÜN √çCH CHO B·ªò NH·ªö CHAT ---
def format_chat_history_for_prompt(history_list):
    """Chuy·ªÉn ƒë·ªïi list (q, a) th√†nh string cho prompt."""
    if not history_list:
        return "Kh√¥ng c√≥"
    formatted = []
    for q, a in history_list:
        formatted.append(f"Ng∆∞·ªùi d√πng: {q}\nTr·ª£ l√Ω: {a}")
    return "\n\n".join(formatted)

# --- ROUTE H·ªéI ƒê√ÅP (ƒê√É C·∫¨P NH·∫¨T V·ªöI B·ªò NH·ªö CHAT) ---
@app.route('/ask', methods=['POST'])
def ask():
    if not chain_is_ready: 
        return jsonify({'error': 'H·ªá th·ªëng AI (vƒÉn b·∫£n) ch∆∞a s·∫µn s√†ng.'}), 503

    user_question = request.json.get('question')
    if not user_question: 
        return jsonify({'error': 'Vui l√≤ng nh·∫≠p c√¢u h·ªèi.'}), 400

    try:
        # --- LOGIC B·ªò NH·ªö ƒê·ªÜM ---
        k_memory = 3 # Gi·ªØ 3 l∆∞·ª£t h·ªôi tho·∫°i cu·ªëi
        history_list = session.get('chat_history', [])
        history_string = format_chat_history_for_prompt(history_list)
        
        # Invoke chain v·ªõi input l√† dictionary
        result = chain.invoke({
            "question": user_question,
            "chat_history": history_string
        })
        
        answer = result.get("answer", "Kh√¥ng c√≥ c√¢u tr·∫£ l·ªùi.")
        sources = result.get("sources", [])

        # C·∫≠p nh·∫≠t l·ªãch s·ª≠ m·ªõi v√† l∆∞u l·∫°i v√†o session
        history_list.append((user_question, answer))
        session['chat_history'] = history_list[-k_memory:] # Ch·ªâ gi·ªØ 3 l∆∞·ª£t Q&A cu·ªëi
        # --- K·∫æT TH√öC LOGIC B·ªò NH·ªö ƒê·ªÜM ---

        # In debug ra backend
        print(f"\n{'='*50}\nüéØ C√ÇU H·ªéI: {user_question}\nü§ñ TR·∫¢ L·ªúI: {answer}\nüìö NGU·ªíN:")
        formatted_sources_for_json = []
        if sources:
             for i, doc in enumerate(sources[:5]):
                metadata = doc.metadata
                doc_date = metadata.get('date', 'Kh√¥ng r√µ')
                source_file = metadata.get('source', 'Kh√¥ng r√µ')
                source_filename = os.path.basename(source_file) if source_file != 'Kh√¥ng r√µ' else 'Kh√¥ng r√µ'
                page_num = metadata.get('page', None)
                display_page = page_num + 1 if isinstance(page_num, int) else 'N/A'
                content_preview = ' '.join(doc.page_content.split()[:20])
                print(f"   [{i+1}] Ng√†y: {doc_date} | Ngu·ªìn: {source_filename} | Trang: {display_page}")
                formatted_sources_for_json.append({
                    "date": doc_date, "filename": source_filename, "page": display_page,
                    "content_preview": content_preview
                })
        print(f"{'='*50}\n")
        
        return jsonify({
            'answer': answer
            # 'sources': formatted_sources_for_json 
        })

    except Exception as e:
        print(f"‚ùå L·ªói khi x·ª≠ l√Ω c√¢u h·ªèi: {e}")
        traceback.print_exc()
        return jsonify({'error': 'ƒê√£ c√≥ l·ªói x·∫£y ra trong qu√° tr√¨nh x·ª≠ l√Ω c√¢u h·ªèi c·ªßa b·∫°n.'}), 500

# --- ROUTE T√åM KI·∫æM H√åNH ·∫¢NH (KH√îNG ƒê·ªîI) ---
@app.route('/search_image', methods=['POST'])
def handle_search_image():
    if not image_search_is_ready:
        return jsonify({'error': 'H·ªá th·ªëng t√¨m ki·∫øm ·∫£nh ch∆∞a s·∫µn s√†ng.'}), 503

    user_query = request.json.get('query')
    if not user_query:
        return jsonify({'error': 'Vui l√≤ng nh·∫≠p n·ªôi dung t√¨m ki·∫øm.'}), 400
    
    try:
        search_results = search_images(user_query, top_k=2) # T√¨m ki·∫øm top 2 ·∫£nh
        return jsonify({'results': search_results})
    
    except Exception as e:
        print(f"‚ùå L·ªói khi t√¨m ki·∫øm ·∫£nh: {e}")
        traceback.print_exc()
        return jsonify({'error': 'ƒê√£ c√≥ l·ªói x·∫£y ra trong qu√° tr√¨nh t√¨m ki·∫øm h√¨nh ·∫£nh.'}), 500

# --- ROUTE UPLOAD PDF (ƒê√É ƒê∆Ø·ª¢C B·∫¢O V·ªÜ V√Ä C·∫¨P NH·∫¨T) ---
@app.route('/upload_pdf', methods=['POST'])
@admin_required # <-- Ch·ªâ admin m·ªõi ƒë∆∞·ª£c truy c·∫≠p
def handle_upload_pdf():
    # Ki·ªÉm tra file v√† ng√†y th√°ng t·ª´ form
    if 'pdf_file' not in request.files:
        return jsonify({'error': 'Kh√¥ng t√¨m th·∫•y file (key=pdf_file).'}), 400
    if 'document_date' not in request.form:
         return jsonify({'error': 'Kh√¥ng t√¨m th·∫•y ng√†y (key=document_date).'}), 400
         
    file = request.files['pdf_file']
    document_date_str = request.form['document_date']
    
    if file.filename == '':
        return jsonify({'error': 'Kh√¥ng c√≥ file n√†o ƒë∆∞·ª£c ch·ªçn.'}), 400
    if not document_date_str:
        return jsonify({'error': 'Vui l√≤ng ch·ªçn ng√†y cho vƒÉn b·∫£n.'}), 400
        
    if file and file.filename.lower().endswith('.pdf'):
        filepath = "" # Kh·ªüi t·∫°o ƒë·ªÉ d√πng trong finally
        try:
            filename = secure_filename(file.filename)
            filepath = os.path.join(app.config['UPLOAD_FOLDER'], filename)
            file.save(filepath)
            
            print(f"\n--- ADMIN: B·∫ÆT ƒê·∫¶U B·ªî SUNG D·ªÆ LI·ªÜU M·ªöI ---")
            print(f"üìÑ ƒêang x·ª≠ l√Ω file: {filepath}")

            loader_pdf = PyPDFLoader(filepath)
            pages_pdf = loader_pdf.load()

            # S·ª≠ d·ª•ng char_splitter ƒë√£ kh·ªüi t·∫°o to√†n c·ª•c
            pdf_char_split = char_splitter.split_documents(pages_pdf)

            # G·∫Øn tem th·ªùi gian t·ª´ form
            upload_date = date.fromisoformat(document_date_str).isoformat()
            print(f"üè∑Ô∏è  ƒêang g·∫Øn tem th·ªùi gian '{upload_date}' cho {len(pdf_char_split)} chunks...")
            
            for doc in pdf_char_split:
                # Ghi ƒë√® ho·∫∑c th√™m date, gi·ªØ l·∫°i source g·ªëc t·ª´ PyPDFLoader
                doc.metadata = {**doc.metadata, "date": upload_date} 

            if pdf_char_split:
                # S·ª≠ d·ª•ng vectorstore to√†n c·ª•c
                vectorstore.add_documents(pdf_char_split)
                count = vectorstore._collection.count()
                print(f"‚úÖ ƒê√£ th√™m th√†nh c√¥ng {len(pdf_char_split)} ƒëo·∫°n vƒÉn b·∫£n m·ªõi.")
                print(f"   -> T·ªïng s·ªë t√†i li·ªáu hi·ªán t·∫°i: {count}")
            
            return jsonify({
                'message': f'ƒê√£ x·ª≠ l√Ω th√†nh c√¥ng file: {filename}',
                'chunks_added': len(pdf_char_split),
                'date_added': upload_date,
                'total_documents': count
            }), 200

        except Exception as e:
            print(f"‚ùå L·ªói khi x·ª≠ l√Ω file upload: {e}")
            traceback.print_exc()
            return jsonify({'error': f'ƒê√£ c√≥ l·ªói x·∫£y ra khi x·ª≠ l√Ω file: {e}'}), 500
        finally:
             # D·ªçn d·∫πp file t·∫°m sau khi x·ª≠ l√Ω
            if os.path.exists(filepath):
                os.remove(filepath)
    else:
        return jsonify({'error': 'File kh√¥ng h·ª£p l·ªá. Ch·ªâ ch·∫•p nh·∫≠n file .pdf'}), 400

# ===========================
# --- KH·ªêI 5: CH·∫†Y APP ---
# ===========================
if __name__ == '__main__':
    app.run(host='0.0.0.0', port=5000, debug=True)